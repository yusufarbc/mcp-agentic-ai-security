# MCP Code Execution Demo

This project demonstrates how an AI agent, based on Model Context Protocol (MCP) principles, can work more efficiently by using **Code Execution** instead of the inefficient "tool calling" method.

## Project Purpose

In traditional methods, an agent tries to fetch all data from a database and process it within its own context window. This is both slow and consumes a large number of tokens.

In this demo, the agent:
1.  Writes a **script** to fetch and filter the data.
2.  Executes this code in a secure environment.
3.  Retrieves only the filtered, clean result.

This method provides **up to 98% token savings** and is much faster.

## Setup

Install the necessary dependencies before running the project:

```bash
npm install
```

## Usage

There are two different operating methods in this project:

### 1. Manual Agent Scenario (`agent_script.ts`)

In this scenario, you run the manually written version of the ideal code that the agent should write.

```bash
npx ts-node agent_script.ts
```

**Expected Output:**
Only 3 orders with "Pending" status and an amount over $50,000 will be listed.

### 2. LLM Powered Agent (`llm_agent.ts`)

In this scenario, the **Gemini 2.0 Flash-Lite** model understands the user's natural language request ("Find and list orders over $50,000 that are only 'Pending' from a large sales database"), dynamically writes the necessary filtering code, and executes it.

**Requirements:**
- Create a `.env` file and add your Gemini API key:
  ```env
  GEMINI_API_KEY=your_api_key
  ```

**Run:**

```bash
npx ts-node llm_agent.ts
```

The agent will do the following:
1.  Analyze the request.
2.  Generate TypeScript code that uses the `servers/crm-database` module.
3.  Save the code to the `generated_task.ts` file.
4.  Execute the code and print the result to the screen.

## File Structure

- `servers/crm-database/`: Example database simulation.
- `agent_script.ts`: Manually optimized example code.
- `llm_agent.ts`: Agent that dynamically generates and executes code using the Gemini API.
- `generated_task.ts`: Temporary code file generated by the LLM.
